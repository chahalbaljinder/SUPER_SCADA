{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "561e9e43-10a5-446a-b780-4dd9803ff023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.2)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: prophet in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.1.5)\n",
      "Collecting prophet\n",
      "  Downloading prophet-1.1.6-py3-none-win_amd64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.1.1)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.1.2-cp311-cp311-win_amd64.whl.metadata (59 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: cmdstanpy>=1.0.4 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prophet) (1.2.4)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prophet) (3.8.4)\n",
      "Requirement already satisfied: holidays<1,>=0.25 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prophet) (0.56)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prophet) (4.65.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prophet) (6.4.4)\n",
      "Requirement already satisfied: stanio<2.0.0,>=0.4.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cmdstanpy>=1.0.4->prophet) (0.5.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (3.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.36.1->prophet) (0.4.6)\n",
      "Downloading pandas-2.2.3-cp311-cp311-win_amd64.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/11.6 MB 5.6 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.8/11.6 MB 4.4 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.6/11.6 MB 4.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.4/11.6 MB 4.1 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.5/11.6 MB 4.0 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.2/11.6 MB 4.0 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.0/11.6 MB 4.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.8/11.6 MB 4.0 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 7.6/11.6 MB 3.9 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.4/11.6 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.2/11.6 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.0/11.6 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.0/11.6 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.6/11.6 MB 3.9 MB/s eta 0:00:00\n",
      "Downloading prophet-1.1.6-py3-none-win_amd64.whl (13.3 MB)\n",
      "   ---------------------------------------- 0.0/13.3 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/13.3 MB 4.2 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.6/13.3 MB 3.8 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 2.4/13.3 MB 3.8 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.4/13.3 MB 3.9 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 4.2/13.3 MB 3.9 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 5.0/13.3 MB 3.8 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 5.8/13.3 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.6/13.3 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 7.3/13.3 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 8.1/13.3 MB 3.8 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 9.2/13.3 MB 3.8 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 10.0/13.3 MB 3.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.7/13.3 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.5/13.3 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 12.3/13.3 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.1/13.3 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.3/13.3 MB 3.8 MB/s eta 0:00:00\n",
      "Downloading numpy-2.1.2-cp311-cp311-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/12.9 MB 4.2 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.6/12.9 MB 4.0 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.4/12.9 MB 3.9 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.4/12.9 MB 3.9 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 4.2/12.9 MB 3.9 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 5.0/12.9 MB 3.9 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 5.8/12.9 MB 3.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.6/12.9 MB 3.9 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 7.3/12.9 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 8.1/12.9 MB 3.9 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 9.2/12.9 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 10.0/12.9 MB 3.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.7/12.9 MB 3.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.5/12.9 MB 3.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.3/12.9 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 3.8 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy, pandas, prophet\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.1\n",
      "    Uninstalling numpy-2.1.1:\n",
      "      Successfully uninstalled numpy-2.1.1\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.3\n",
      "    Uninstalling pandas-2.2.3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~otebook (C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~otebook (C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: Could not install packages due to an OSError: [('c:\\\\users\\\\admin\\\\appdata\\\\local\\\\programs\\\\python\\\\python311\\\\lib\\\\site-packages\\\\pandas\\\\tests\\\\arrays\\\\period\\\\__pycache__\\\\test_reductions.cpython-311.pyc.2337334748592', 'C:\\\\Users\\\\admin\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\pandas\\\\tests\\\\arrays\\\\~eriod\\\\__pycache__\\\\test_reductions.cpython-311.pyc.2337334748592', \"[Errno 2] No such file or directory: 'c:\\\\\\\\users\\\\\\\\admin\\\\\\\\appdata\\\\\\\\local\\\\\\\\programs\\\\\\\\python\\\\\\\\python311\\\\\\\\lib\\\\\\\\site-packages\\\\\\\\pandas\\\\\\\\tests\\\\\\\\arrays\\\\\\\\period\\\\\\\\__pycache__\\\\\\\\test_reductions.cpython-311.pyc.2337334748592'\")]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pandas prophet numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23b4e419-1451-43a7-8e30-b106988b7e6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "`np.float_` was removed in the NumPy 2.0 release. Use `np.float64` instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtsa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mseasonal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m seasonal_decompose\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprophet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Prophet\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\prophet\\__init__.py:7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) 2017-present, Facebook, Inc.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# All rights reserved.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the BSD-style license found in the\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree. An additional grant\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# of patent rights can be found in the PATENTS file in the same directory.\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprophet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mforecaster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Prophet\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m     10\u001b[0m about \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\prophet\\forecaster.py:28\u001b[0m\n\u001b[0;32m     25\u001b[0m logger\u001b[38;5;241m.\u001b[39msetLevel(logging\u001b[38;5;241m.\u001b[39mINFO)\n\u001b[0;32m     26\u001b[0m NANOSECONDS_TO_SECONDS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mProphet\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;250;43m    \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"Prophet forecaster.\u001b[39;49;00m\n\u001b[0;32m     30\u001b[0m \n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;43;03m    Parameters\u001b[39;49;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;124;43;03m    holidays_mode: 'additive' or 'multiplicative'. Defaults to seasonality_mode.\u001b[39;49;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;124;43;03m    \"\"\"\u001b[39;49;00m\n\u001b[0;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgrowth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlinear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[43m            \u001b[49m\u001b[43mholidays_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\prophet\\forecaster.py:459\u001b[0m, in \u001b[0;36mProphet\u001b[1;34m()\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    452\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchangepoints_t \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m])  \u001b[38;5;66;03m# dummy changepoint\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfourier_series\u001b[39m(\n\u001b[0;32m    456\u001b[0m     dates: pd\u001b[38;5;241m.\u001b[39mSeries,\n\u001b[0;32m    457\u001b[0m     period: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m],\n\u001b[0;32m    458\u001b[0m     series_order: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m--> 459\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDArray[\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat_\u001b[49m]:\n\u001b[0;32m    460\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Provides Fourier series components with the specified frequency\u001b[39;00m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;124;03m    and order.\u001b[39;00m\n\u001b[0;32m    462\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;124;03m    Matrix with seasonality features.\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (series_order \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\__init__.py:414\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr], name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __expired_attributes__:\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` was removed in the NumPy 2.0 release. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    416\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m__expired_attributes__[attr]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    417\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    418\u001b[0m     )\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchararray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    421\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    422\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`np.chararray` is deprecated and will be removed from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    423\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe main namespace in the future. Use an array with a string \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    424\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor bytes dtype instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: `np.float_` was removed in the NumPy 2.0 release. Use `np.float64` instead."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from prophet import Prophet\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Load Dataset\n",
    "df = pd.read_csv(r'C:\\Users\\admin\\Desktop\\offline nbeats\\Final_Training_Dataset.csv')  # Replace with your dataset path\n",
    "\n",
    "# Data Preprocessing\n",
    "# Correct datetime format to handle '2018-08-06T09:25:42.000Z'\n",
    "df['Dt'] = pd.to_datetime(df['Dt'], format='%Y-%m-%dT%H:%M:%S.%fZ', errors='coerce')\n",
    "\n",
    "# Check for any rows where parsing failed\n",
    "invalid_dates = df[df['Dt'].isnull()]\n",
    "if not invalid_dates.empty:\n",
    "    print(\"Some dates could not be parsed:\")\n",
    "    print(invalid_dates)\n",
    "\n",
    "# Drop rows with invalid dates if needed\n",
    "df = df.dropna(subset=['Dt'])\n",
    "\n",
    "# Continue with setting the index\n",
    "df.set_index('Dt', inplace=True)\n",
    "\n",
    "# Filtering based on user input for stn no and EqN\n",
    "stn_no = input(\"Enter station number (or 'all' for all stations): \")\n",
    "eqn_no = input(\"Enter equipment number (or 'all' for all equipment): \")\n",
    "\n",
    "# Apply filters\n",
    "if stn_no.lower() != 'all':\n",
    "    df = df[df['stn'] == int(stn_no)]\n",
    "if eqn_no.lower() != 'all':\n",
    "    df = df[df['EqN'] == int(eqn_no)]\n",
    "\n",
    "# Aggregating the Footfall at Hourly Level\n",
    "hourly_footfall = df.resample('H').count()  # Hourly footfall\n",
    "\n",
    "# Set frequency for hourly_footfall\n",
    "hourly_footfall = hourly_footfall.asfreq('H')\n",
    "\n",
    "# Time-Series Decomposition\n",
    "decomposition = seasonal_decompose(hourly_footfall['_id'], model='additive')\n",
    "fig = decomposition.plot()\n",
    "fig.suptitle('Time-Series Decomposition: Trend, Seasonal, and Residuals', y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# Specify Forecast Period\n",
    "start_date = pd.to_datetime(input(\"Enter forecast start date (YYYY-MM-DD): \"))\n",
    "end_date = pd.to_datetime(input(\"Enter forecast end date (YYYY-MM-DD): \"))\n",
    "forecast_period = (end_date - start_date).days * 24  # Forecast period in hours\n",
    "\n",
    "# File Path Base\n",
    "base_path = r'C:\\Users\\admin\\Desktop\\airline\\sensor-file-ridership\\output of sensors'\n",
    "\n",
    "# Prophet Model - Alternative Time-Series Forecasting\n",
    "hourly_footfall_prophet = hourly_footfall.reset_index()\n",
    "\n",
    "# Ensure the DataFrame only has 'timestamp' and 'transaction_id' after resetting the index\n",
    "hourly_footfall_prophet = hourly_footfall_prophet[['Dt', '_id']]\n",
    "hourly_footfall_prophet.columns = ['ds', 'y']  # Rename columns for Prophet\n",
    "\n",
    "# Convert 'ds' to datetime and 'y' to numeric\n",
    "hourly_footfall_prophet['ds'] = pd.to_datetime(hourly_footfall_prophet['ds'])\n",
    "hourly_footfall_prophet['y'] = pd.to_numeric(hourly_footfall_prophet['y'], errors='coerce', downcast='float')\n",
    "\n",
    "# Ensure y is converted to the correct dtype (float64)\n",
    "hourly_footfall_prophet['y'] = hourly_footfall_prophet['y'].astype(np.float64)\n",
    "\n",
    "# Apply log transformation (add small constant to avoid log(0) error)\n",
    "hourly_footfall_prophet['y'] = np.log1p(hourly_footfall_prophet['y'])\n",
    "\n",
    "# Fit Prophet model\n",
    "prophet_model = Prophet()\n",
    "prophet_model.fit(hourly_footfall_prophet)\n",
    "\n",
    "# Create future dataframe starting from the user-specified start_date\n",
    "future_df = pd.date_range(start=start_date, end=end_date, freq='H')\n",
    "future_prophet = pd.DataFrame({'ds': future_df})\n",
    "\n",
    "# Generate predictions\n",
    "forecast_prophet = prophet_model.predict(future_prophet)\n",
    "\n",
    "# Inverse the log transformation\n",
    "forecast_prophet['yhat'] = np.expm1(forecast_prophet['yhat'])\n",
    "\n",
    "# Creating a DataFrame for Prophet Forecast\n",
    "prophet_forecast_df = forecast_prophet[['ds', 'yhat']]\n",
    "prophet_forecast_df.columns = ['Dt', 'id']\n",
    "\n",
    "# Round off the Prophet forecasted data\n",
    "prophet_forecast_df['id'] = prophet_forecast_df['id'].round()\n",
    "\n",
    "# Save Prophet Forecast to CSV\n",
    "prophet_forecast_df.to_csv(os.path.join(base_path, f'hourly_footfall_forecast_prophet_{stn_no}_{eqn_no}.csv'), index=False)\n",
    "\n",
    "# Aggregation of Prophet Forecast\n",
    "daily_forecast_prophet = prophet_forecast_df.copy()\n",
    "daily_forecast_prophet.set_index('Dt', inplace=True)\n",
    "\n",
    "# Aggregation: Daily, Weekly, Monthly, Yearly\n",
    "daily_forecast_prophet_resampled = daily_forecast_prophet.resample('D').sum()\n",
    "weekly_forecast_prophet_resampled = daily_forecast_prophet.resample('W').sum()\n",
    "monthly_forecast_prophet_resampled = daily_forecast_prophet.resample('M').sum()\n",
    "yearly_forecast_prophet_resampled = daily_forecast_prophet.resample('Y').sum()\n",
    "\n",
    "# Weekend and Weekday Aggregation\n",
    "weekend_forecast_prophet_resampled = daily_forecast_prophet[daily_forecast_prophet.index.dayofweek >= 5].resample('D').sum()\n",
    "weekday_forecast_prophet_resampled = daily_forecast_prophet[daily_forecast_prophet.index.dayofweek < 5].resample('D').sum()\n",
    "\n",
    "# Add week of year and day of week to weekly forecast\n",
    "weekly_forecast_prophet_resampled['week_of_year'] = weekly_forecast_prophet_resampled.index.isocalendar().week\n",
    "weekly_forecast_prophet_resampled['day_of_week'] = weekly_forecast_prophet_resampled.index.day_name()\n",
    "\n",
    "# Add month name to monthly forecast\n",
    "monthly_forecast_prophet_resampled['month_name'] = monthly_forecast_prophet_resampled.index.month_name()\n",
    "\n",
    "# Add day of week to weekend and weekday forecasts\n",
    "weekend_forecast_prophet_resampled['day_of_week'] = weekend_forecast_prophet_resampled.index.day_name()\n",
    "weekday_forecast_prophet_resampled['day_of_week'] = weekday_forecast_prophet_resampled.index.day_name()\n",
    "\n",
    "# Save Aggregated Forecast Data to CSV\n",
    "daily_forecast_prophet_resampled.to_csv(os.path.join(base_path, f'daily_forecast_prophet_{stn_no}_{eqn_no}.csv'))\n",
    "weekly_forecast_prophet_resampled.to_csv(os.path.join(base_path, f'weekly_forecast_prophet_{stn_no}_{eqn_no}.csv'))\n",
    "monthly_forecast_prophet_resampled.to_csv(os.path.join(base_path, f'monthly_forecast_prophet_{stn_no}_{eqn_no}.csv'))\n",
    "yearly_forecast_prophet_resampled.to_csv(os.path.join(base_path, f'yearly_forecast_prophet_{stn_no}_{eqn_no}.csv'))\n",
    "weekend_forecast_prophet_resampled.to_csv(os.path.join(base_path, f'weekend_forecast_prophet_{stn_no}_{eqn_no}.csv'))\n",
    "weekday_forecast_prophet_resampled.to_csv(os.path.join(base_path, f'weekday_forecast_prophet_{stn_no}_{eqn_no}.csv'))\n",
    "\n",
    "# Aggregation of Prophet Forecast Data by Hour of Day\n",
    "prophet_forecast_df['hour'] = prophet_forecast_df['Dt'].dt.hour\n",
    "hourly_aggr_prophet = prophet_forecast_df.groupby('hour')['id'].sum().reset_index()\n",
    "\n",
    "# Save Aggregated Hourly Prophet Forecast Data to CSV\n",
    "hourly_aggr_prophet.to_csv(os.path.join(base_path, f'hourly_aggr_prophet_forecast_{stn_no}_{eqn_no}.csv'), index=False)\n",
    "\n",
    "# Display the Prophet Forecast DataFrame\n",
    "print(prophet_forecast_df.head())\n",
    "\n",
    "print(\"Files saved to their respective destinations\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2f5231-84ea-413f-b215-e0d45732c10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def plot_raw_data(data_type, file_paths):\n",
    "    \"\"\"\n",
    "    Plots raw data based on the specified data type from the given file paths.\n",
    "    Additionally plots weekday vs. weekend data if 'weekday_vs_weekend' is specified.\n",
    "    \n",
    "    Parameters:\n",
    "    - data_type (str): Type of data to plot ('daily', 'weekly', 'monthly', 'yearly', 'weekend', 'weekday', 'weekday_vs_weekend', 'hourly').\n",
    "    - file_paths (dict): Dictionary containing file paths for each data type.\n",
    "    \"\"\"\n",
    "    if data_type == 'weekday_vs_weekend':\n",
    "        # Load Weekend Dataset\n",
    "        weekend_file_path = file_paths['weekend']\n",
    "        weekend_df = pd.read_csv(weekend_file_path)\n",
    "        weekend_df['Dt'] = pd.to_datetime(weekend_df['Dt'])\n",
    "        weekend_df.set_index('Dt', inplace=True)\n",
    "        \n",
    "        # Load Weekday Dataset\n",
    "        weekday_file_path = file_paths['weekday']\n",
    "        weekday_df = pd.read_csv(weekday_file_path)\n",
    "        weekday_df['Dt'] = pd.to_datetime(weekday_df['Dt'])\n",
    "        weekday_df.set_index('Dt', inplace=True)\n",
    "        \n",
    "        # Print the raw data to check its structure\n",
    "        print(\"Raw weekend data:\")\n",
    "        print(weekend_df.head())\n",
    "        print(\"Raw weekday data:\")\n",
    "        print(weekday_df.head())\n",
    "        \n",
    "        # Plotting Weekday vs Weekend Footfall Over Time\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(weekend_df.index, weekend_df['id'], label='Weekend Footfall', color='purple')\n",
    "        plt.plot(weekday_df.index, weekday_df['id'], label='Weekday Footfall', color='cyan')\n",
    "        plt.title('Weekday vs Weekend Footfall Over Time')\n",
    "        plt.xlabel('dt')\n",
    "        plt.ylabel('IDs')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        # Aggregating total transactions for weekday vs weekend\n",
    "        total_weekend = weekend_df['id'].sum()\n",
    "        total_weekday = weekday_df['id'].sum()\n",
    "        \n",
    "        # Creating a DataFrame for aggregation\n",
    "        aggregated_df = pd.DataFrame({\n",
    "            'Footfall Type': ['Weekday', 'Weekend'],\n",
    "            'Total Transactions IDs': [total_weekday, total_weekend]\n",
    "        })\n",
    "        \n",
    "        # Plotting Aggregated Weekday vs Weekend Data\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.bar(aggregated_df['Footfall Type'], aggregated_df['Total Transactions IDs'], color=['cyan', 'purple'])\n",
    "        plt.title('Total Weekday vs Weekend Footfall')\n",
    "        plt.xlabel('Footfall Type')\n",
    "        plt.ylabel('Total IDs')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    elif data_type == 'monthly':\n",
    "        # Load Daily Dataset\n",
    "        daily_file_path = file_paths['daily']\n",
    "        daily_df = pd.read_csv(daily_file_path)\n",
    "        daily_df['Dt'] = pd.to_datetime(daily_df['Dt'])\n",
    "        daily_df.set_index('Dt', inplace=True)\n",
    "        \n",
    "        # Aggregate Data to Monthly Totals\n",
    "        monthly_footfall = daily_df.resample('M').sum()  # Aggregating daily data into monthly totals\n",
    "        monthly_footfall['month_name'] = monthly_footfall.index.month_name()\n",
    "        monthly_footfall['year'] = monthly_footfall.index.year\n",
    "        \n",
    "        # Print the aggregated data\n",
    "        print(\"Monthly Aggregated Data:\")\n",
    "        print(monthly_footfall.head())\n",
    "        \n",
    "        # Optionally, save the aggregated data to a new CSV file\n",
    "        aggregated_file_path = os.path.join(base_path, f'monthly_aggregated_data_{stn_no}_{eqn_no}.csv')\n",
    "        monthly_footfall.to_csv(aggregated_file_path)\n",
    "        print(f\"Aggregated data saved to {aggregated_file_path}\")\n",
    "        \n",
    "        # Plotting the aggregated monthly data\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        monthly_footfall.plot(y='id', kind='bar', color='orange', legend=False)\n",
    "        plt.title('Monthly Footfall Aggregated from Daily Data')\n",
    "        plt.xlabel('Month')\n",
    "        plt.ylabel('IDs')\n",
    "        plt.xticks(ticks=range(len(monthly_footfall)), labels=monthly_footfall['month_name'], rotation=45)\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    elif data_type == 'yearly':\n",
    "        # Load Yearly Dataset\n",
    "        yearly_file_path = file_paths['yearly']\n",
    "        yearly_df = pd.read_csv(yearly_file_path)\n",
    "        yearly_df['Dt'] = pd.to_datetime(yearly_df['Dt'])\n",
    "        yearly_df.set_index('Dt', inplace=True)\n",
    "        yearly_df['year'] = yearly_df.index.year\n",
    "        \n",
    "        # Print the raw data to check its structure\n",
    "        print(\"Raw yearly data:\")\n",
    "        print(yearly_df.head())\n",
    "        \n",
    "        # Plotting the yearly data\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        yearly_df.groupby('year').sum().plot(y='id', kind='bar', color='blue', legend=False)\n",
    "        plt.title('Yearly Footfall')\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('IDs')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    elif data_type == 'weekly':\n",
    "        # Load Weekly Dataset\n",
    "        weekly_file_path = file_paths['weekly']\n",
    "        weekly_df = pd.read_csv(weekly_file_path)\n",
    "        weekly_df['Dt'] = pd.to_datetime(weekly_df['Dt'])\n",
    "        weekly_df.set_index('Dt', inplace=True)\n",
    "        \n",
    "        # Compute Week of Month\n",
    "        weekly_df['week_of_month'] = weekly_df.index.to_series().apply(lambda x: (x.day - 1) // 7 + 1)\n",
    "        \n",
    "        # Filter to show only the first 4 weeks of the month\n",
    "        weekly_df = weekly_df[weekly_df['week_of_month'] <= 4]\n",
    "        \n",
    "        # Print the raw data to check its structure\n",
    "        print(\"Raw weekly data:\")\n",
    "        print(weekly_df.head())\n",
    "        \n",
    "        # Plotting the weekly data\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        weekly_df.groupby('week_of_month').sum().plot(y='id', kind='bar', color='blue', legend=False)\n",
    "        plt.title('Weekly Footfall Aggregated by Week of Month (First 4 Weeks)')\n",
    "        plt.xlabel('Week of Month')\n",
    "        plt.ylabel('IDs')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    \n",
    "    elif data_type == 'weekend':\n",
    "        # Load Weekend Dataset\n",
    "        weekend_file_path = file_paths['weekend']\n",
    "        weekend_df = pd.read_csv(weekend_file_path)\n",
    "        weekend_df['Dt'] = pd.to_datetime(weekend_df['Dt'])\n",
    "        weekend_df.set_index('Dt', inplace=True)\n",
    "        weekend_df['day_of_week'] = weekend_df.index.day_name()\n",
    "        \n",
    "        # Print the raw data to check its structure\n",
    "        print(\"Raw weekend data:\")\n",
    "        print(weekend_df.head())\n",
    "        \n",
    "        # Plotting the weekend data\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        weekend_df.groupby('day_of_week').sum().plot(y='id', kind='bar', color='green', legend=False)\n",
    "        plt.title('Weekend Footfall Aggregated by Day of Week')\n",
    "        plt.xlabel('Day of Week')\n",
    "        plt.ylabel('IDs')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    \n",
    "    elif data_type == 'weekday':\n",
    "        # Load Weekday Dataset\n",
    "        weekday_file_path = file_paths['weekday']\n",
    "        weekday_df = pd.read_csv(weekday_file_path)\n",
    "        weekday_df['Dt'] = pd.to_datetime(weekday_df['Dt'])\n",
    "        weekday_df.set_index('Dt', inplace=True)\n",
    "        weekday_df['day_of_week'] = weekday_df.index.day_name()\n",
    "        \n",
    "        # Print the raw data to check its structure\n",
    "        print(\"Raw weekday data:\")\n",
    "        print(weekday_df.head())\n",
    "        \n",
    "        # Plotting the weekday data\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        weekday_df.groupby('day_of_week').sum().plot(y='id', kind='bar', color='red', legend=False)\n",
    "        plt.title('Weekday Footfall Aggregated by Day of Week')\n",
    "        plt.xlabel('Day of Week')\n",
    "        plt.ylabel('IDs')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    elif data_type == 'hourly':\n",
    "        # Load Hourly Aggregated Forecast Dataset\n",
    "        hourly_file_path = file_paths['hourly']\n",
    "        hourly_df = pd.read_csv(hourly_file_path)\n",
    "        '''hourly_df['hour'] = pd.to_datetime(hourly_df['hour'])\n",
    "        hourly_df.set_index('hour', inplace=True)'''\n",
    "        \n",
    "        # Print the raw data to check its structure\n",
    "        print(\"Raw hourly aggregated forecast data:\")\n",
    "        print(hourly_df.head())\n",
    "    \n",
    "        # Plotting the hourly aggregated forecast data\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(hourly_df.index, hourly_df['id'], label='Hourly Footfall Forecast', color='orange')\n",
    "        plt.title('Hourly Aggregated Forecast Footfall')\n",
    "        plt.xlabel('Hour')\n",
    "        plt.ylabel('IDs')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    \n",
    "    else:\n",
    "        # Load Dataset\n",
    "        file_path = file_paths.get(data_type)\n",
    "        if file_path:\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Data Preprocessing\n",
    "            df['Dt'] = pd.to_datetime(df['Dt'])\n",
    "            df.set_index('Dt', inplace=True)\n",
    "            \n",
    "            # Print the raw data to check its structure\n",
    "            print(f\"Raw data for {data_type}:\")\n",
    "            print(df.head())\n",
    "\n",
    "            # Plotting the raw data\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.plot(df.index, df['id'], label=f'Raw {data_type.capitalize()} Footfall', color='blue')\n",
    "            plt.title(f'Raw {data_type.capitalize()} Footfall Over Time')\n",
    "            plt.xlabel('Dt')\n",
    "            plt.ylabel('IDs')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"File path for '{data_type}' data type is not provided.\")\n",
    "\n",
    "def main():\n",
    "    # Define the base path for output files\n",
    "    base_path = r'C:\\Users\\admin\\Desktop\\airline\\sensor-file-ridership\\output of sensors'\n",
    "    \n",
    "    # Get station number and equation number from the user\n",
    "    stn_no = input(\"Enter the station number (stn_no): \").strip()\n",
    "    eqn_no = input(\"Enter the equation number (eqn_no): \").strip()\n",
    "    \n",
    "    # Define file paths for different forecast types\n",
    "    file_paths = {\n",
    "        'daily': os.path.join(base_path, f'daily_forecast_prophet_{stn_no}_{eqn_no}.csv'),\n",
    "        'weekly': os.path.join(base_path, f'weekly_forecast_prophet_{stn_no}_{eqn_no}.csv'),\n",
    "        'monthly': os.path.join(base_path, f'monthly_forecast_prophet_{stn_no}_{eqn_no}.csv'),\n",
    "        'yearly': os.path.join(base_path, f'yearly_forecast_prophet_{stn_no}_{eqn_no}.csv'),\n",
    "        'weekend': os.path.join(base_path, f'weekend_forecast_prophet_{stn_no}_{eqn_no}.csv'),\n",
    "        'weekday': os.path.join(base_path, f'weekday_forecast_prophet_{stn_no}_{eqn_no}.csv'),\n",
    "        'hourly': os.path.join(base_path, f'hourly_aggr_prophet_forecast_{stn_no}_{eqn_no}.csv')  # Path for hourly aggregated forecast\n",
    "    }\n",
    "\n",
    "    # Get user input for data type\n",
    "    data_type = input(\"Enter the data type to plot ('daily', 'weekly', 'monthly', 'yearly', 'weekday_vs_weekend', 'weekend', 'weekday', 'hourly'): \").strip().lower()\n",
    "\n",
    "    # Plot the data based on user input\n",
    "    plot_raw_data(data_type, file_paths)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
