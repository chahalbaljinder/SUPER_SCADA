{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b4e419-1451-43a7-8e30-b106988b7e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from prophet import Prophet\n",
    "import os\n",
    "\n",
    "# Load Dataset\n",
    "df = pd.read_csv('transaction_updated.csv')  # Replace with your dataset path\n",
    "\n",
    "# Data Preprocessing\n",
    "df['Dt'] = pd.to_datetime(df['Dt'], format='%Y-%m-%dT%H-%M-%S.%fZ', errors='coerce')\n",
    "\n",
    "# Check for any rows where parsing failed\n",
    "invalid_dates = df[df['Dt'].isnull()]\n",
    "if not invalid_dates.empty:\n",
    "    print(\"Some dates could not be parsed:\")\n",
    "    print(invalid_dates)\n",
    "\n",
    "# Drop rows with invalid dates if needed\n",
    "df = df.dropna(subset=['Dt'])\n",
    "\n",
    "# Continue with setting the index\n",
    "df.set_index('Dt', inplace=True)\n",
    "\n",
    "# Filtering based on user input for stn no and EqN\n",
    "stn_no = input(\"Enter station number (or 'all' for all stations): \")\n",
    "eqn_no = input(\"Enter equipment number (or 'all' for all equipment): \")\n",
    "\n",
    "# Apply filters\n",
    "if stn_no.lower() != 'all':\n",
    "    df = df[df['stn'] == int(stn)]\n",
    "if eqn_no.lower() != 'all':\n",
    "    df = df[df['EqN'] == int(eqn_no)]\n",
    "\n",
    "# Aggregating the Footfall at Hourly Level\n",
    "hourly_footfall = df.resample('H').count()  # Hourly footfall\n",
    "\n",
    "# Set frequency for hourly_footfall\n",
    "hourly_footfall = hourly_footfall.asfreq('H')\n",
    "\n",
    "# Time-Series Decomposition\n",
    "decomposition = seasonal_decompose(hourly_footfall['id'], model='additive')\n",
    "fig = decomposition.plot()\n",
    "fig.suptitle('Time-Series Decomposition: Trend, Seasonal, and Residuals', y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# Specify Forecast Period\n",
    "start_date = pd.to_datetime(input(\"Enter forecast start date (YYYY-MM-DD): \"))\n",
    "end_date = pd.to_datetime(input(\"Enter forecast end date (YYYY-MM-DD): \"))\n",
    "forecast_period = (end_date - start_date).days * 24  # Forecast period in hours\n",
    "\n",
    "# File Path Base\n",
    "base_path = r'C:\\Users\\admin\\Desktop\\airline\\sensor-file-ridership\\output of sensors'\n",
    "\n",
    "# Prophet Model - Alternative Time-Series Forecasting\n",
    "hourly_footfall_prophet = hourly_footfall.reset_index()\n",
    "\n",
    "# Ensure the DataFrame only has 'timestamp' and 'transaction_id' after resetting the index\n",
    "hourly_footfall_prophet = hourly_footfall_prophet[['Dt', 'id']]\n",
    "hourly_footfall_prophet.columns = ['ds', 'y']  # Rename columns for Prophet\n",
    "\n",
    "# Convert 'ds' to datetime and 'y' to numeric\n",
    "hourly_footfall_prophet['ds'] = pd.to_datetime(hourly_footfall_prophet['ds'])\n",
    "hourly_footfall_prophet['y'] = pd.to_numeric(hourly_footfall_prophet['y'], errors='coerce')\n",
    "\n",
    "# Fit Prophet model\n",
    "prophet_model = Prophet()\n",
    "prophet_model.fit(hourly_footfall_prophet)\n",
    "\n",
    "# Create future dataframe starting from the user-specified start_date\n",
    "future_df = pd.date_range(start=start_date, end=end_date, freq='H')\n",
    "future_prophet = pd.DataFrame({'ds': future_df})\n",
    "forecast_prophet = prophet_model.predict(future_prophet)\n",
    "\n",
    "# Creating a DataFrame for Prophet Forecast\n",
    "prophet_forecast_df = forecast_prophet[['ds', 'yhat']]\n",
    "prophet_forecast_df.columns = ['Dt', 'id']\n",
    "\n",
    "# Round off the Prophet forecasted data\n",
    "prophet_forecast_df['id'] = prophet_forecast_df['id'].round()\n",
    "\n",
    "# Save Prophet Forecast to CSV\n",
    "prophet_forecast_df.to_csv(os.path.join(base_path, f'hourly_footfall_forecast_prophet_{stn_no}_{eqn_no}.csv'), index=False)\n",
    "\n",
    "# Aggregation of Prophet Forecast\n",
    "daily_forecast_prophet = prophet_forecast_df.copy()\n",
    "daily_forecast_prophet.set_index('Dt', inplace=True)\n",
    "\n",
    "# Aggregation: Daily, Weekly, Monthly, Yearly\n",
    "daily_forecast_prophet_resampled = daily_forecast_prophet.resample('D').sum()\n",
    "weekly_forecast_prophet_resampled = daily_forecast_prophet.resample('W').sum()\n",
    "monthly_forecast_prophet_resampled = daily_forecast_prophet.resample('M').sum()\n",
    "yearly_forecast_prophet_resampled = daily_forecast_prophet.resample('Y').sum()\n",
    "\n",
    "# Weekend and Weekday Aggregation\n",
    "weekend_forecast_prophet_resampled = daily_forecast_prophet[daily_forecast_prophet.index.dayofweek >= 5].resample('D').sum()\n",
    "weekday_forecast_prophet_resampled = daily_forecast_prophet[daily_forecast_prophet.index.dayofweek < 5].resample('D').sum()\n",
    "\n",
    "# Add week of year and day of week to weekly forecast\n",
    "weekly_forecast_prophet_resampled['week_of_year'] = weekly_forecast_prophet_resampled.index.isocalendar().week\n",
    "weekly_forecast_prophet_resampled['day_of_week'] = weekly_forecast_prophet_resampled.index.day_name()\n",
    "\n",
    "# Add month name to monthly forecast\n",
    "monthly_forecast_prophet_resampled['month_name'] = monthly_forecast_prophet_resampled.index.month_name()\n",
    "\n",
    "# Add day of week to weekend and weekday forecasts\n",
    "weekend_forecast_prophet_resampled['day_of_week'] = weekend_forecast_prophet_resampled.index.day_name()\n",
    "weekday_forecast_prophet_resampled['day_of_week'] = weekday_forecast_prophet_resampled.index.day_name()\n",
    "\n",
    "# Save Aggregated Forecast Data to CSV\n",
    "daily_forecast_prophet_resampled.to_csv(os.path.join(base_path, f'daily_forecast_prophet_{stn_no}_{eqn_no}.csv'))\n",
    "weekly_forecast_prophet_resampled.to_csv(os.path.join(base_path, f'weekly_forecast_prophet_{stn_no}_{eqn_no}.csv'))\n",
    "monthly_forecast_prophet_resampled.to_csv(os.path.join(base_path, f'monthly_forecast_prophet_{stn_no}_{eqn_no}.csv'))\n",
    "yearly_forecast_prophet_resampled.to_csv(os.path.join(base_path, f'yearly_forecast_prophet_{stn_no}_{eqn_no}.csv'))\n",
    "weekend_forecast_prophet_resampled.to_csv(os.path.join(base_path, f'weekend_forecast_prophet_{stn_no}_{eqn_no}.csv'))\n",
    "weekday_forecast_prophet_resampled.to_csv(os.path.join(base_path, f'weekday_forecast_prophet_{stn_no}_{eqn_no}.csv'))\n",
    "\n",
    "# Aggregation of Prophet Forecast Data by Hour of Day\n",
    "prophet_forecast_df['hour'] = prophet_forecast_df['Dt'].dt.hour\n",
    "hourly_aggr_prophet = prophet_forecast_df.groupby('hour')['id'].sum().reset_index()\n",
    "\n",
    "# Save Aggregated Hourly Prophet Forecast Data to CSV\n",
    "hourly_aggr_prophet.to_csv(os.path.join(base_path, f'hourly_aggr_prophet_forecast_{stn_no}_{eqn_no}.csv'), index=False)\n",
    "\n",
    "# Display the Prophet Forecast DataFrame\n",
    "print(prophet_forecast_df.head())\n",
    "\n",
    "print(\"Files saved to their respective destinations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2f5231-84ea-413f-b215-e0d45732c10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def plot_raw_data(data_type, file_paths):\n",
    "    \"\"\"\n",
    "    Plots raw data based on the specified data type from the given file paths.\n",
    "    Additionally plots weekday vs. weekend data if 'weekday_vs_weekend' is specified.\n",
    "    \n",
    "    Parameters:\n",
    "    - data_type (str): Type of data to plot ('daily', 'weekly', 'monthly', 'yearly', 'weekend', 'weekday', 'weekday_vs_weekend', 'hourly').\n",
    "    - file_paths (dict): Dictionary containing file paths for each data type.\n",
    "    \"\"\"\n",
    "    if data_type == 'weekday_vs_weekend':\n",
    "        # Load Weekend Dataset\n",
    "        weekend_file_path = file_paths['weekend']\n",
    "        weekend_df = pd.read_csv(weekend_file_path)\n",
    "        weekend_df['Dt'] = pd.to_datetime(weekend_df['Dt'])\n",
    "        weekend_df.set_index('Dt', inplace=True)\n",
    "        \n",
    "        # Load Weekday Dataset\n",
    "        weekday_file_path = file_paths['weekday']\n",
    "        weekday_df = pd.read_csv(weekday_file_path)\n",
    "        weekday_df['Dt'] = pd.to_datetime(weekday_df['Dt'])\n",
    "        weekday_df.set_index('Dt', inplace=True)\n",
    "        \n",
    "        # Print the raw data to check its structure\n",
    "        print(\"Raw weekend data:\")\n",
    "        print(weekend_df.head())\n",
    "        print(\"Raw weekday data:\")\n",
    "        print(weekday_df.head())\n",
    "        \n",
    "        # Plotting Weekday vs Weekend Footfall Over Time\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(weekend_df.index, weekend_df['id'], label='Weekend Footfall', color='purple')\n",
    "        plt.plot(weekday_df.index, weekday_df['id'], label='Weekday Footfall', color='cyan')\n",
    "        plt.title('Weekday vs Weekend Footfall Over Time')\n",
    "        plt.xlabel('dt')\n",
    "        plt.ylabel('IDs')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        # Aggregating total transactions for weekday vs weekend\n",
    "        total_weekend = weekend_df['id'].sum()\n",
    "        total_weekday = weekday_df['id'].sum()\n",
    "        \n",
    "        # Creating a DataFrame for aggregation\n",
    "        aggregated_df = pd.DataFrame({\n",
    "            'Footfall Type': ['Weekday', 'Weekend'],\n",
    "            'Total Transactions IDs': [total_weekday, total_weekend]\n",
    "        })\n",
    "        \n",
    "        # Plotting Aggregated Weekday vs Weekend Data\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.bar(aggregated_df['Footfall Type'], aggregated_df['Total Transactions IDs'], color=['cyan', 'purple'])\n",
    "        plt.title('Total Weekday vs Weekend Footfall')\n",
    "        plt.xlabel('Footfall Type')\n",
    "        plt.ylabel('Total IDs')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    elif data_type == 'monthly':\n",
    "        # Load Daily Dataset\n",
    "        daily_file_path = file_paths['daily']\n",
    "        daily_df = pd.read_csv(daily_file_path)\n",
    "        daily_df['Dt'] = pd.to_datetime(daily_df['Dt'])\n",
    "        daily_df.set_index('Dt', inplace=True)\n",
    "        \n",
    "        # Aggregate Data to Monthly Totals\n",
    "        monthly_footfall = daily_df.resample('M').sum()  # Aggregating daily data into monthly totals\n",
    "        monthly_footfall['month_name'] = monthly_footfall.index.month_name()\n",
    "        monthly_footfall['year'] = monthly_footfall.index.year\n",
    "        \n",
    "        # Print the aggregated data\n",
    "        print(\"Monthly Aggregated Data:\")\n",
    "        print(monthly_footfall.head())\n",
    "        \n",
    "        # Optionally, save the aggregated data to a new CSV file\n",
    "        aggregated_file_path = os.path.join(base_path, f'monthly_aggregated_data_{stn_no}_{eqn_no}.csv')\n",
    "        monthly_footfall.to_csv(aggregated_file_path)\n",
    "        print(f\"Aggregated data saved to {aggregated_file_path}\")\n",
    "        \n",
    "        # Plotting the aggregated monthly data\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        monthly_footfall.plot(y='id', kind='bar', color='orange', legend=False)\n",
    "        plt.title('Monthly Footfall Aggregated from Daily Data')\n",
    "        plt.xlabel('Month')\n",
    "        plt.ylabel('IDs')\n",
    "        plt.xticks(ticks=range(len(monthly_footfall)), labels=monthly_footfall['month_name'], rotation=45)\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    elif data_type == 'yearly':\n",
    "        # Load Yearly Dataset\n",
    "        yearly_file_path = file_paths['yearly']\n",
    "        yearly_df = pd.read_csv(yearly_file_path)\n",
    "        yearly_df['Dt'] = pd.to_datetime(yearly_df['Dt'])\n",
    "        yearly_df.set_index('Dt', inplace=True)\n",
    "        yearly_df['year'] = yearly_df.index.year\n",
    "        \n",
    "        # Print the raw data to check its structure\n",
    "        print(\"Raw yearly data:\")\n",
    "        print(yearly_df.head())\n",
    "        \n",
    "        # Plotting the yearly data\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        yearly_df.groupby('year').sum().plot(y='id', kind='bar', color='blue', legend=False)\n",
    "        plt.title('Yearly Footfall')\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('IDs')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    elif data_type == 'weekly':\n",
    "        # Load Weekly Dataset\n",
    "        weekly_file_path = file_paths['weekly']\n",
    "        weekly_df = pd.read_csv(weekly_file_path)\n",
    "        weekly_df['Dt'] = pd.to_datetime(weekly_df['Dt'])\n",
    "        weekly_df.set_index('Dt', inplace=True)\n",
    "        \n",
    "        # Compute Week of Month\n",
    "        weekly_df['week_of_month'] = weekly_df.index.to_series().apply(lambda x: (x.day - 1) // 7 + 1)\n",
    "        \n",
    "        # Filter to show only the first 4 weeks of the month\n",
    "        weekly_df = weekly_df[weekly_df['week_of_month'] <= 4]\n",
    "        \n",
    "        # Print the raw data to check its structure\n",
    "        print(\"Raw weekly data:\")\n",
    "        print(weekly_df.head())\n",
    "        \n",
    "        # Plotting the weekly data\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        weekly_df.groupby('week_of_month').sum().plot(y='id', kind='bar', color='blue', legend=False)\n",
    "        plt.title('Weekly Footfall Aggregated by Week of Month (First 4 Weeks)')\n",
    "        plt.xlabel('Week of Month')\n",
    "        plt.ylabel('IDs')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    \n",
    "    elif data_type == 'weekend':\n",
    "        # Load Weekend Dataset\n",
    "        weekend_file_path = file_paths['weekend']\n",
    "        weekend_df = pd.read_csv(weekend_file_path)\n",
    "        weekend_df['Dt'] = pd.to_datetime(weekend_df['Dt'])\n",
    "        weekend_df.set_index('Dt', inplace=True)\n",
    "        weekend_df['day_of_week'] = weekend_df.index.day_name()\n",
    "        \n",
    "        # Print the raw data to check its structure\n",
    "        print(\"Raw weekend data:\")\n",
    "        print(weekend_df.head())\n",
    "        \n",
    "        # Plotting the weekend data\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        weekend_df.groupby('day_of_week').sum().plot(y='id', kind='bar', color='green', legend=False)\n",
    "        plt.title('Weekend Footfall Aggregated by Day of Week')\n",
    "        plt.xlabel('Day of Week')\n",
    "        plt.ylabel('IDs')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    \n",
    "    elif data_type == 'weekday':\n",
    "        # Load Weekday Dataset\n",
    "        weekday_file_path = file_paths['weekday']\n",
    "        weekday_df = pd.read_csv(weekday_file_path)\n",
    "        weekday_df['Dt'] = pd.to_datetime(weekday_df['Dt'])\n",
    "        weekday_df.set_index('Dt', inplace=True)\n",
    "        weekday_df['day_of_week'] = weekday_df.index.day_name()\n",
    "        \n",
    "        # Print the raw data to check its structure\n",
    "        print(\"Raw weekday data:\")\n",
    "        print(weekday_df.head())\n",
    "        \n",
    "        # Plotting the weekday data\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        weekday_df.groupby('day_of_week').sum().plot(y='id', kind='bar', color='red', legend=False)\n",
    "        plt.title('Weekday Footfall Aggregated by Day of Week')\n",
    "        plt.xlabel('Day of Week')\n",
    "        plt.ylabel('IDs')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    elif data_type == 'hourly':\n",
    "        # Load Hourly Aggregated Forecast Dataset\n",
    "        hourly_file_path = file_paths['hourly']\n",
    "        hourly_df = pd.read_csv(hourly_file_path)\n",
    "        '''hourly_df['hour'] = pd.to_datetime(hourly_df['hour'])\n",
    "        hourly_df.set_index('hour', inplace=True)'''\n",
    "        \n",
    "        # Print the raw data to check its structure\n",
    "        print(\"Raw hourly aggregated forecast data:\")\n",
    "        print(hourly_df.head())\n",
    "    \n",
    "        # Plotting the hourly aggregated forecast data\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(hourly_df.index, hourly_df['id'], label='Hourly Footfall Forecast', color='orange')\n",
    "        plt.title('Hourly Aggregated Forecast Footfall')\n",
    "        plt.xlabel('Hour')\n",
    "        plt.ylabel('IDs')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    \n",
    "    else:\n",
    "        # Load Dataset\n",
    "        file_path = file_paths.get(data_type)\n",
    "        if file_path:\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Data Preprocessing\n",
    "            df['Dt'] = pd.to_datetime(df['Dt'])\n",
    "            df.set_index('Dt', inplace=True)\n",
    "            \n",
    "            # Print the raw data to check its structure\n",
    "            print(f\"Raw data for {data_type}:\")\n",
    "            print(df.head())\n",
    "\n",
    "            # Plotting the raw data\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.plot(df.index, df['id'], label=f'Raw {data_type.capitalize()} Footfall', color='blue')\n",
    "            plt.title(f'Raw {data_type.capitalize()} Footfall Over Time')\n",
    "            plt.xlabel('Dt')\n",
    "            plt.ylabel('IDs')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"File path for '{data_type}' data type is not provided.\")\n",
    "\n",
    "def main():\n",
    "    # Define the base path for output files\n",
    "    base_path = r'C:\\Users\\admin\\Desktop\\airline\\sensor-file-ridership\\output of sensors'\n",
    "    \n",
    "    # Get station number and equation number from the user\n",
    "    stn_no = input(\"Enter the station number (stn_no): \").strip()\n",
    "    eqn_no = input(\"Enter the equation number (eqn_no): \").strip()\n",
    "    \n",
    "    # Define file paths for different forecast types\n",
    "    file_paths = {\n",
    "        'daily': os.path.join(base_path, f'daily_forecast_prophet_{stn_no}_{eqn_no}.csv'),\n",
    "        'weekly': os.path.join(base_path, f'weekly_forecast_prophet_{stn_no}_{eqn_no}.csv'),\n",
    "        'monthly': os.path.join(base_path, f'monthly_forecast_prophet_{stn_no}_{eqn_no}.csv'),\n",
    "        'yearly': os.path.join(base_path, f'yearly_forecast_prophet_{stn_no}_{eqn_no}.csv'),\n",
    "        'weekend': os.path.join(base_path, f'weekend_forecast_prophet_{stn_no}_{eqn_no}.csv'),\n",
    "        'weekday': os.path.join(base_path, f'weekday_forecast_prophet_{stn_no}_{eqn_no}.csv'),\n",
    "        'hourly': os.path.join(base_path, f'hourly_aggr_prophet_forecast_{stn_no}_{eqn_no}.csv')  # Path for hourly aggregated forecast\n",
    "    }\n",
    "\n",
    "    # Get user input for data type\n",
    "    data_type = input(\"Enter the data type to plot ('daily', 'weekly', 'monthly', 'yearly', 'weekday_vs_weekend', 'weekend', 'weekday', 'hourly'): \").strip().lower()\n",
    "\n",
    "    # Plot the data based on user input\n",
    "    plot_raw_data(data_type, file_paths)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
